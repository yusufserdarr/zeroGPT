{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35ca7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4cbca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               metin      etiket\n",
      "0  DÃ¼n akÅŸam arkadaÅŸlarÄ±mla beraber yemeÄŸe gittik...       insan\n",
      "1                TÃ¼rkiye'nin en gÃ¼zel ÅŸehri Ordudur.       insan\n",
      "2  Bu yemeÄŸin tarifi bana bizzat annem tarafÄ±ndan...       insan\n",
      "3  Kitap ÅŸimdilik sÄ±kÄ±cÄ± gidiyor ama ilerleyen za...       insan\n",
      "4  Pazar sabahlarÄ± uzun sÃ¼re yatmak acayip keyifl...       insan\n",
      "5  Sinematografik bir deneyim olarak, sÃ¶z konusu ...  yapay_zeka\n",
      "6  TÃ¼rkiye Cumhuriyeti'nin gÃ¼ney kÄ±yÄ± ÅŸeridi, yaz...  yapay_zeka\n",
      "7  Ä°nternet kaynaklarÄ±ndan elde edilen bu yemek r...  yapay_zeka\n",
      "8  Okuma eylemine konu olan eser, baÅŸlangÄ±Ã§ itiba...  yapay_zeka\n",
      "9  HaftanÄ±n son gÃ¼nÃ¼ olan Pazar, sabah saatlerind...  yapay_zeka\n"
     ]
    }
   ],
   "source": [
    "# Ã–rnek verilerimizi oluÅŸturalÄ±m\n",
    "data = {\n",
    "    'metin': [\n",
    "        # Ä°nsan tarafÄ±ndan yazÄ±lmÄ±ÅŸ metinler\n",
    "        \"DÃ¼n akÅŸam arkadaÅŸlarÄ±mla beraber yemeÄŸe gittik ve harikaydÄ±. \",\n",
    "        \"TÃ¼rkiye'nin en gÃ¼zel ÅŸehri Ordudur.\",\n",
    "        \"Bu yemeÄŸin tarifi bana bizzat annem tarafÄ±ndan verildi.\",\n",
    "        \"Kitap ÅŸimdilik sÄ±kÄ±cÄ± gidiyor ama ilerleyen zamanlarda eÄŸlenceli olacaktÄ±r.\",\n",
    "        \"Pazar sabahlarÄ± uzun sÃ¼re yatmak acayip keyiflidir.\",\n",
    "        \n",
    "        # Yapay zeka tarafÄ±ndan Ã¼retilmiÅŸ metinler\n",
    "        \"Sinematografik bir deneyim olarak, sÃ¶z konusu film, izleyicilere unutulmaz anlar yaÅŸatmayÄ± vaat etmektedir.\",\n",
    "        \"TÃ¼rkiye Cumhuriyeti'nin gÃ¼ney kÄ±yÄ± ÅŸeridi, yaz aylarÄ±nda turistik faaliyetler iÃ§in Ã¶nemli bir merkez konumundadÄ±r.\",\n",
    "        \"Ä°nternet kaynaklarÄ±ndan elde edilen bu yemek reÃ§etesi, kiÅŸisel tercihlere gÃ¶re modifiye edilmiÅŸtir.\",\n",
    "        \"Okuma eylemine konu olan eser, baÅŸlangÄ±Ã§ itibarÄ±yla sÃ¼rÃ¼kleyici bir anlatÄ±m yapÄ±sÄ± sergilemektedir.\",\n",
    "        \"HaftanÄ±n son gÃ¼nÃ¼ olan Pazar, sabah saatlerinde gerÃ§ekleÅŸtirilen kahvaltÄ± aktivitesi iÃ§in sÄ±klÄ±kla tercih edilir.\"\n",
    "    ],\n",
    "    'etiket': [\n",
    "        'insan', 'insan', 'insan', 'insan', 'insan',\n",
    "        'yapay_zeka', 'yapay_zeka', 'yapay_zeka', 'yapay_zeka', 'yapay_zeka'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Veriyi pandas DataFrame'ine dÃ¶nÃ¼ÅŸtÃ¼relim\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Veri setimize bir gÃ¶z atalÄ±m\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb28db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri eÄŸitim ve test setlerine ayrÄ±ldÄ±.\n",
      "EÄŸitim seti boyutu: 8\n",
      "Test seti boyutu: 2\n"
     ]
    }
   ],
   "source": [
    "# Metinler (X) ve etiketler (y) olarak ayÄ±ralÄ±m\n",
    "X = df['metin']\n",
    "y = df['etiket']\n",
    "\n",
    "# Veri setini %80 eÄŸitim, %20 test olarak bÃ¶lelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Veri eÄŸitim ve test setlerine ayrÄ±ldÄ±.\")\n",
    "print(\"EÄŸitim seti boyutu:\", len(X_train))\n",
    "print(\"Test seti boyutu:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854885ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metinler baÅŸarÄ±yla sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.\n"
     ]
    }
   ],
   "source": [
    "# Bir TF-IDF Vectorizer nesnesi oluÅŸturalÄ±m\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorizer'Ä± sadece eÄŸitim verisiyle eÄŸitelim ve hem eÄŸitim hem de test verisini dÃ¶nÃ¼ÅŸtÃ¼relim\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Metinler baÅŸarÄ±yla sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd064f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model baÅŸarÄ±yla eÄŸitildi!\n"
     ]
    }
   ],
   "source": [
    "# Lojistik Regresyon modelini oluÅŸturalÄ±m\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Modeli eÄŸitim verileriyle eÄŸitelim\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model baÅŸarÄ±yla eÄŸitildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "554c22df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelin test doÄŸruluÄŸu: 50.00%\n",
      "\n",
      "--- Test Seti Tahminleri ---\n",
      "Metin: Okuma eylemine konu olan eser, baÅŸlangÄ±Ã§ itibarÄ±yla sÃ¼rÃ¼kleyici bir anlatÄ±m yapÄ±sÄ± sergilemektedir.\n",
      "GerÃ§ek Etiket: yapay_zeka, Tahmin: yapay_zeka\n",
      "\n",
      "Metin: TÃ¼rkiye'nin en gÃ¼zel ÅŸehri Ordudur.\n",
      "GerÃ§ek Etiket: insan, Tahmin: yapay_zeka\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test verileriyle tahmin yapalÄ±m\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Tahminleri gerÃ§ek etiketlerle karÅŸÄ±laÅŸtÄ±ralÄ±m\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Modelin test doÄŸruluÄŸu: {accuracy * 100:.2f}%\")\n",
    "print(\"\\n--- Test Seti Tahminleri ---\")\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"Metin: {X_test.iloc[i]}\")\n",
    "    print(f\"GerÃ§ek Etiket: {y_test.iloc[i]}, Tahmin: {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e82dd858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin: 'Bu konuyu hiÃ§ anlamadÄ±m, birisi bana yardÄ±mcÄ± olabilir mi?' ---> Tahmin: INSAN\n",
      "Metin: 'bugÃ¼n kÃ¼tÃ¼phaneye ders Ã§alÄ±ÅŸmaya geldim ama hala Ã§alÄ±ÅŸmaya baÅŸlayamadÄ±m.' ---> Tahmin: INSAN\n"
     ]
    }
   ],
   "source": [
    "# Test etmek iÃ§in yeni metinler\n",
    "yeni_metinler = [\n",
    "    \"Bu konuyu hiÃ§ anlamadÄ±m, birisi bana yardÄ±mcÄ± olabilir mi?\", # Beklenen: insan\n",
    "    \"bugÃ¼n kÃ¼tÃ¼phaneye ders Ã§alÄ±ÅŸmaya geldim ama hala Ã§alÄ±ÅŸmaya baÅŸlayamadÄ±m.\" # Beklenen: yapay_zeka\n",
    "]\n",
    "\n",
    "# Metinleri aynÄ± vectorizer ile dÃ¶nÃ¼ÅŸtÃ¼relim\n",
    "yeni_metinler_tfidf = vectorizer.transform(yeni_metinler)\n",
    "\n",
    "# Model ile tahmin yapalÄ±m (DÃœZELTÄ°LMÄ°Å SATIR)\n",
    "yeni_tahminler = model.predict(yeni_metinler_tfidf)\n",
    "\n",
    "for metin, tahmin in zip(yeni_metinler, yeni_tahminler):\n",
    "    print(f\"Metin: '{metin}' ---> Tahmin: {tahmin.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2c06a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ä°nsan verisi yÃ¼klendi, Ã¶rnek:\n",
      "                                             content category  \\\n",
      "0  DÄ±ÅŸiÅŸleri BakanÄ± DavutoÄŸlu, Yunanistan ile TÃ¼r...    dÃ¼nya   \n",
      "1  Ä°srail Gazze Åeridi nin kuzeyindeki bir tarlay...    dÃ¼nya   \n",
      "2  LÃ¼bnan Ä±n baÅŸkenti Beyrut ta dÃ¼zenlenen bombal...    dÃ¼nya   \n",
      "3  KKTC de Sendikal Platform genel grev baÅŸlattÄ±....    dÃ¼nya   \n",
      "4  TÃ¼rkiye den yola Ã§Ä±kan BaÅŸak Bulut, SeÃ§il Ã–znu...    dÃ¼nya   \n",
      "\n",
      "                                            headline  label  \n",
      "0                             'Ortak vizyonumuz var'      0  \n",
      "1          Ä°srail'den Gazze Åeridi'ne hava saldÄ±rÄ±sÄ±      0  \n",
      "2        Cenaze iÃ§in geniÅŸ gÃ¼venlik Ã¶nlemleri alÄ±ndÄ±      0  \n",
      "3                  GÃ¶zaltÄ±ndaki sendikacÄ±lar serbest      0  \n",
      "4  Bisikletle Asya'da 3 bin kilometre yol katettiler      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Temiz TÃ¼rkÃ§e insan yazÄ±sÄ± verisini oku\n",
    "df = pd.read_csv(\"temizlenmis_turkce_veri.csv\")\n",
    "\n",
    "# Etiket ekle (0 = Human)\n",
    "df[\"label\"] = 0\n",
    "\n",
    "print(\"âœ… Ä°nsan verisi yÃ¼klendi, Ã¶rnek:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e971d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final veri seti oluÅŸturuldu (38791 satÄ±r).\n",
      "                                                 content  label\n",
      "37401  Siirt te cinnet geÃ§iren bir kiÅŸi pompalÄ± tÃ¼fek...      0\n",
      "23647  ÃœnlÃ¼ BolÅŸoy Tiyatrosu nun Ã¶nceki gÃ¼n kezzap sa...      0\n",
      "2957   Suudi Arabistan merkezli Arabian Construction ...      0\n",
      "32312  McLaren, Abu Dabi GP de sahip olduklarÄ± hÄ±zÄ±n,...      0\n",
      "29636  PTT 1. Lig takÄ±mlarÄ±ndan Boluspor un KulÃ¼p BaÅŸ...      0\n"
     ]
    }
   ],
   "source": [
    "# Åimdilik Ã¶rnek birkaÃ§ yapay metin\n",
    "ai_texts = [\n",
    "    \"Yapay zekÃ¢ sistemleri, veri analizi sÃ¼reÃ§lerinde devrim yaratÄ±yor.\",\n",
    "    \"GeleceÄŸin ÅŸehirleri tamamen akÄ±llÄ± teknolojilerle yÃ¶netilecek.\",\n",
    "    \"Makine Ã¶ÄŸrenmesi modelleri artÄ±k tÄ±pta erken teÅŸhislerde kullanÄ±lÄ±yor.\",\n",
    "    \"DoÄŸal dil iÅŸleme, mÃ¼ÅŸteri hizmetlerinde otomatik yanÄ±t sistemlerini gÃ¼Ã§lendiriyor.\",\n",
    "    \"Otonom araÃ§lar, trafiÄŸi daha gÃ¼venli hale getirmek iÃ§in geliÅŸtiriliyor.\"\n",
    "]\n",
    "\n",
    "ai_df = pd.DataFrame({\"content\": ai_texts, \"label\": 1})\n",
    "\n",
    "# Her iki veriyi birleÅŸtir\n",
    "merged = pd.concat([\n",
    "    df.rename(columns={\"content\": \"content\"})[[\"content\", \"label\"]],\n",
    "    ai_df\n",
    "], ignore_index=True)\n",
    "\n",
    "merged.to_csv(\"final_dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… Final veri seti oluÅŸturuldu ({len(merged)} satÄ±r).\")\n",
    "print(merged.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84b47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model eÄŸitimi tamamlandÄ±!\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7759\n",
      "\n",
      "    accuracy                           1.00      7759\n",
      "   macro avg       1.00      1.00      1.00      7759\n",
      "weighted avg       1.00      1.00      1.00      7759\n",
      "\n",
      "ğŸ”¹ DoÄŸruluk (accuracy): 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Veriyi yÃ¼kle\n",
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "\n",
    "# Ã–zellik Ã§Ä±karÄ±mÄ±\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"content\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# EÄŸitim ve test verisi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"âœ… Model eÄŸitimi tamamlandÄ±!\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ğŸ”¹ DoÄŸruluk (accuracy): {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BugÃ¼n hava oldukÃ§a gÃ¼zeldi, kahvemi alÄ±p sahilde yÃ¼rÃ¼yÃ¼ÅŸ yaptÄ±m.\n",
      "â†’ Tahmin: ğŸ§â€â™‚ï¸ Ä°nsan\n",
      "\n",
      " \n",
      "â†’ Tahmin: ğŸ§â€â™‚ï¸ Ä°nsan\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"BugÃ¼n hava oldukÃ§a gÃ¼zeldi, kahvemi alÄ±p sahilde yÃ¼rÃ¼yÃ¼ÅŸ yaptÄ±m.\",  # insan\n",
    "    \"\"  # yapay\n",
    "]\n",
    "\n",
    "sample_features = vectorizer.transform(sample_texts)\n",
    "predictions = model.predict(sample_features)\n",
    "\n",
    "for text, pred in zip(sample_texts, predictions):\n",
    "    etiket = \"ğŸ§â€â™‚ï¸ Ä°nsan\" if pred == 0 else \"ğŸ¤– Yapay ZekÃ¢\"\n",
    "    print(f\"\\n{text}\\nâ†’ Tahmin: {etiket}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42807ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
