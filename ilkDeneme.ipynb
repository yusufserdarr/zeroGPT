{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35ca7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kütüphaneler başarıyla yüklendi!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Kütüphaneler başarıyla yüklendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4cbca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               metin      etiket\n",
      "0  Dün akşam arkadaşlarımla beraber yemeğe gittik...       insan\n",
      "1                Türkiye'nin en güzel şehri Ordudur.       insan\n",
      "2  Bu yemeğin tarifi bana bizzat annem tarafından...       insan\n",
      "3  Kitap şimdilik sıkıcı gidiyor ama ilerleyen za...       insan\n",
      "4  Pazar sabahları uzun süre yatmak acayip keyifl...       insan\n",
      "5  Sinematografik bir deneyim olarak, söz konusu ...  yapay_zeka\n",
      "6  Türkiye Cumhuriyeti'nin güney kıyı şeridi, yaz...  yapay_zeka\n",
      "7  İnternet kaynaklarından elde edilen bu yemek r...  yapay_zeka\n",
      "8  Okuma eylemine konu olan eser, başlangıç itiba...  yapay_zeka\n",
      "9  Haftanın son günü olan Pazar, sabah saatlerind...  yapay_zeka\n"
     ]
    }
   ],
   "source": [
    "# Örnek verilerimizi oluşturalım\n",
    "data = {\n",
    "    'metin': [\n",
    "        # İnsan tarafından yazılmış metinler\n",
    "        \"Dün akşam arkadaşlarımla beraber yemeğe gittik ve harikaydı. \",\n",
    "        \"Türkiye'nin en güzel şehri Ordudur.\",\n",
    "        \"Bu yemeğin tarifi bana bizzat annem tarafından verildi.\",\n",
    "        \"Kitap şimdilik sıkıcı gidiyor ama ilerleyen zamanlarda eğlenceli olacaktır.\",\n",
    "        \"Pazar sabahları uzun süre yatmak acayip keyiflidir.\",\n",
    "        \n",
    "        # Yapay zeka tarafından üretilmiş metinler\n",
    "        \"Sinematografik bir deneyim olarak, söz konusu film, izleyicilere unutulmaz anlar yaşatmayı vaat etmektedir.\",\n",
    "        \"Türkiye Cumhuriyeti'nin güney kıyı şeridi, yaz aylarında turistik faaliyetler için önemli bir merkez konumundadır.\",\n",
    "        \"İnternet kaynaklarından elde edilen bu yemek reçetesi, kişisel tercihlere göre modifiye edilmiştir.\",\n",
    "        \"Okuma eylemine konu olan eser, başlangıç itibarıyla sürükleyici bir anlatım yapısı sergilemektedir.\",\n",
    "        \"Haftanın son günü olan Pazar, sabah saatlerinde gerçekleştirilen kahvaltı aktivitesi için sıklıkla tercih edilir.\"\n",
    "    ],\n",
    "    'etiket': [\n",
    "        'insan', 'insan', 'insan', 'insan', 'insan',\n",
    "        'yapay_zeka', 'yapay_zeka', 'yapay_zeka', 'yapay_zeka', 'yapay_zeka'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Veriyi pandas DataFrame'ine dönüştürelim\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Veri setimize bir göz atalım\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddb28db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri eğitim ve test setlerine ayrıldı.\n",
      "Eğitim seti boyutu: 8\n",
      "Test seti boyutu: 2\n"
     ]
    }
   ],
   "source": [
    "# Metinler (X) ve etiketler (y) olarak ayıralım\n",
    "X = df['metin']\n",
    "y = df['etiket']\n",
    "\n",
    "# Veri setini %80 eğitim, %20 test olarak bölelim\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Veri eğitim ve test setlerine ayrıldı.\")\n",
    "print(\"Eğitim seti boyutu:\", len(X_train))\n",
    "print(\"Test seti boyutu:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854885ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metinler başarıyla sayısal vektörlere dönüştürüldü.\n"
     ]
    }
   ],
   "source": [
    "# Bir TF-IDF Vectorizer nesnesi oluşturalım\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorizer'ı sadece eğitim verisiyle eğitelim ve hem eğitim hem de test verisini dönüştürelim\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Metinler başarıyla sayısal vektörlere dönüştürüldü.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd064f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla eğitildi!\n"
     ]
    }
   ],
   "source": [
    "# Lojistik Regresyon modelini oluşturalım\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Modeli eğitim verileriyle eğitelim\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Model başarıyla eğitildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "554c22df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelin test doğruluğu: 50.00%\n",
      "\n",
      "--- Test Seti Tahminleri ---\n",
      "Metin: Okuma eylemine konu olan eser, başlangıç itibarıyla sürükleyici bir anlatım yapısı sergilemektedir.\n",
      "Gerçek Etiket: yapay_zeka, Tahmin: yapay_zeka\n",
      "\n",
      "Metin: Türkiye'nin en güzel şehri Ordudur.\n",
      "Gerçek Etiket: insan, Tahmin: yapay_zeka\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test verileriyle tahmin yapalım\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Tahminleri gerçek etiketlerle karşılaştıralım\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Modelin test doğruluğu: {accuracy * 100:.2f}%\")\n",
    "print(\"\\n--- Test Seti Tahminleri ---\")\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"Metin: {X_test.iloc[i]}\")\n",
    "    print(f\"Gerçek Etiket: {y_test.iloc[i]}, Tahmin: {predictions[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e82dd858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metin: 'Bu konuyu hiç anlamadım, birisi bana yardımcı olabilir mi?' ---> Tahmin: INSAN\n",
      "Metin: 'bugün kütüphaneye ders çalışmaya geldim ama hala çalışmaya başlayamadım.' ---> Tahmin: INSAN\n"
     ]
    }
   ],
   "source": [
    "# Test etmek için yeni metinler\n",
    "yeni_metinler = [\n",
    "    \"Bu konuyu hiç anlamadım, birisi bana yardımcı olabilir mi?\", # Beklenen: insan\n",
    "    \"bugün kütüphaneye ders çalışmaya geldim ama hala çalışmaya başlayamadım.\" # Beklenen: yapay_zeka\n",
    "]\n",
    "\n",
    "# Metinleri aynı vectorizer ile dönüştürelim\n",
    "yeni_metinler_tfidf = vectorizer.transform(yeni_metinler)\n",
    "\n",
    "# Model ile tahmin yapalım (DÜZELTİLMİŞ SATIR)\n",
    "yeni_tahminler = model.predict(yeni_metinler_tfidf)\n",
    "\n",
    "for metin, tahmin in zip(yeni_metinler, yeni_tahminler):\n",
    "    print(f\"Metin: '{metin}' ---> Tahmin: {tahmin.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2c06a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ İnsan verisi yüklendi, örnek:\n",
      "                                             content category  \\\n",
      "0  Dışişleri Bakanı Davutoğlu, Yunanistan ile Tür...    dünya   \n",
      "1  İsrail Gazze Şeridi nin kuzeyindeki bir tarlay...    dünya   \n",
      "2  Lübnan ın başkenti Beyrut ta düzenlenen bombal...    dünya   \n",
      "3  KKTC de Sendikal Platform genel grev başlattı....    dünya   \n",
      "4  Türkiye den yola çıkan Başak Bulut, Seçil Öznu...    dünya   \n",
      "\n",
      "                                            headline  label  \n",
      "0                             'Ortak vizyonumuz var'      0  \n",
      "1          İsrail'den Gazze Şeridi'ne hava saldırısı      0  \n",
      "2        Cenaze için geniş güvenlik önlemleri alındı      0  \n",
      "3                  Gözaltındaki sendikacılar serbest      0  \n",
      "4  Bisikletle Asya'da 3 bin kilometre yol katettiler      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Temiz Türkçe insan yazısı verisini oku\n",
    "df = pd.read_csv(\"temizlenmis_turkce_veri.csv\")\n",
    "\n",
    "# Etiket ekle (0 = Human)\n",
    "df[\"label\"] = 0\n",
    "\n",
    "print(\"✅ İnsan verisi yüklendi, örnek:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e971d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final veri seti oluşturuldu (38791 satır).\n",
      "                                                 content  label\n",
      "37401  Siirt te cinnet geçiren bir kişi pompalı tüfek...      0\n",
      "23647  Ünlü Bolşoy Tiyatrosu nun önceki gün kezzap sa...      0\n",
      "2957   Suudi Arabistan merkezli Arabian Construction ...      0\n",
      "32312  McLaren, Abu Dabi GP de sahip oldukları hızın,...      0\n",
      "29636  PTT 1. Lig takımlarından Boluspor un Kulüp Baş...      0\n"
     ]
    }
   ],
   "source": [
    "# Şimdilik örnek birkaç yapay metin\n",
    "ai_texts = [\n",
    "    \"Yapay zekâ sistemleri, veri analizi süreçlerinde devrim yaratıyor.\",\n",
    "    \"Geleceğin şehirleri tamamen akıllı teknolojilerle yönetilecek.\",\n",
    "    \"Makine öğrenmesi modelleri artık tıpta erken teşhislerde kullanılıyor.\",\n",
    "    \"Doğal dil işleme, müşteri hizmetlerinde otomatik yanıt sistemlerini güçlendiriyor.\",\n",
    "    \"Otonom araçlar, trafiği daha güvenli hale getirmek için geliştiriliyor.\"\n",
    "]\n",
    "\n",
    "ai_df = pd.DataFrame({\"content\": ai_texts, \"label\": 1})\n",
    "\n",
    "# Her iki veriyi birleştir\n",
    "merged = pd.concat([\n",
    "    df.rename(columns={\"content\": \"content\"})[[\"content\", \"label\"]],\n",
    "    ai_df\n",
    "], ignore_index=True)\n",
    "\n",
    "merged.to_csv(\"final_dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ Final veri seti oluşturuldu ({len(merged)} satır).\")\n",
    "print(merged.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84b47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model eğitimi tamamlandı!\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7759\n",
      "\n",
      "    accuracy                           1.00      7759\n",
      "   macro avg       1.00      1.00      1.00      7759\n",
      "weighted avg       1.00      1.00      1.00      7759\n",
      "\n",
      "🔹 Doğruluk (accuracy): 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Veriyi yükle\n",
    "df = pd.read_csv(\"final_dataset.csv\")\n",
    "\n",
    "# Özellik çıkarımı\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df[\"content\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Eğitim ve test verisi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Tahmin\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"✅ Model eğitimi tamamlandı!\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"🔹 Doğruluk (accuracy): {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bugün hava oldukça güzeldi, kahvemi alıp sahilde yürüyüş yaptım.\n",
      "→ Tahmin: 🧍‍♂️ İnsan\n",
      "\n",
      " \n",
      "→ Tahmin: 🧍‍♂️ İnsan\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    \"Bugün hava oldukça güzeldi, kahvemi alıp sahilde yürüyüş yaptım.\",  # insan\n",
    "    \"\"  # yapay\n",
    "]\n",
    "\n",
    "sample_features = vectorizer.transform(sample_texts)\n",
    "predictions = model.predict(sample_features)\n",
    "\n",
    "for text, pred in zip(sample_texts, predictions):\n",
    "    etiket = \"🧍‍♂️ İnsan\" if pred == 0 else \"🤖 Yapay Zekâ\"\n",
    "    print(f\"\\n{text}\\n→ Tahmin: {etiket}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42807ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
