#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZeroGPT Final - GerÃ§ek ChatGPT Tespiti
--------------------------------------
GerÃ§ek ChatGPT metinleriyle eÄŸitilmiÅŸ final model
"""
import streamlit as st
import streamlit.components.v1 as components
import joblib
import os
import re
import math
import numpy as np
import pandas as pd
from collections import Counter
from scipy.sparse import hstack

st.set_page_config(
    page_title="ZeroGPT TÃ¼rkÃ§e - Final",
    page_icon="ğŸ¯",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# Minimal CSS - Beyaz arka plan zorla!
st.markdown("""
<style>
    /* Ana arka planÄ± beyaz yap */
    .stApp {
        background-color: #ffffff !important;
    }
    
    /* TÃ¼m metinleri siyah yap */
    .stApp, .stMarkdown, h1, h2, h3, p, div {
        color: #000000 !important;
    }
    
    /* BaÅŸlÄ±klar */
    h1, h2, h3 {
        color: #1f1f1f !important;
    }
    
    /* Buton stili */
    .stButton button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white !important;
        border: none;
        border-radius: 10px;
        padding: 12px 24px;
        font-size: 16px;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    
    /* Metin alanÄ± */
    .stTextArea textarea {
        background-color: #ffffff !important;
        color: #000000 !important;
    }
    
    /* Sidebar gizle */
    [data-testid="stSidebar"] {
        display: none;
    }
</style>
""", unsafe_allow_html=True)

TR_STOPWORDS = {
    "ve","veya","ile","ama","fakat","ancak","Ã§Ã¼nkÃ¼","gibi","daha","Ã§ok",
    "az","bu","ÅŸu","o","bir","iki","Ã¼Ã§","her","hiÃ§","mi","mÄ±","mu","mÃ¼",
    "de","da","ki","iÃ§in","Ã¼zere","olan","olarak","sonra","Ã¶nce","ise",
    "ya","ne","neden","nasÄ±l","hangi","hem","en","ben","sen","biz","siz",
    "onlar","var","yok","diye","kadar","beri","gÃ¶re","raÄŸmen","dolayÄ±"
}

def clean_text(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = re.sub(r"http\S+|www\.\S+", " ", s)
    # Sekmeler ve carriage return'Ã¼ temizle, fakat yeni satÄ±rlarÄ± koru
    s = re.sub(r"[\t\r]+", " ", s)
    # AynÄ± satÄ±rda birden fazla boÅŸluk ve yeni satÄ±rlarÄ± temizle (paragraflar korunur)
    s = re.sub(r" +", " ", s)  # SatÄ±r iÃ§i Ã§oklu boÅŸluklarÄ± dÃ¼zelt
    s = re.sub(r"\n\s*\n", "\n", s)  # Ã‡oklu boÅŸ satÄ±rlarÄ± tek satÄ±ra indir
    return s.strip()

def extract_advanced_features(text: str) -> dict:
    features = {}
    features['text_length'] = len(text)
    features['word_count'] = len(text.split())
    
    sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]
    features['sentence_count'] = len(sentences)
    
    if len(sentences) > 0:
        sent_lengths = [len(s.split()) for s in sentences]
        features['avg_sentence_length'] = np.mean(sent_lengths)
        features['std_sentence_length'] = np.std(sent_lengths) if len(sent_lengths) > 1 else 0
        features['burstiness'] = features['std_sentence_length'] / (features['avg_sentence_length'] + 1e-5)
    else:
        features['avg_sentence_length'] = 0
        features['std_sentence_length'] = 0
        features['burstiness'] = 0
    
    words = re.findall(r'\w+', text.lower(), flags=re.UNICODE)
    if len(words) > 0:
        features['lexical_diversity'] = len(set(words)) / len(words)
        features['avg_word_length'] = np.mean([len(w) for w in words])
        word_counts = Counter(words)
        most_common_count = word_counts.most_common(1)[0][1]
        features['max_word_repetition'] = most_common_count / len(words)
        stopword_count = sum(1 for w in words if w in TR_STOPWORDS)
        features['stopword_ratio'] = stopword_count / len(words)
        digit_words = sum(1 for w in words if any(c.isdigit() for c in w))
        features['digit_word_ratio'] = digit_words / len(words)
    else:
        features['lexical_diversity'] = 0
        features['avg_word_length'] = 0
        features['max_word_repetition'] = 0
        features['stopword_ratio'] = 0
        features['digit_word_ratio'] = 0
    
    if len(text) > 0:
        char_counts = Counter(text.lower())
        total = sum(char_counts.values())
        probs = [c/total for c in char_counts.values()]
        features['char_entropy'] = -sum(p * math.log2(p + 1e-12) for p in probs)
    else:
        features['char_entropy'] = 0
    
    features['comma_count'] = text.count(',')
    features['question_mark_count'] = text.count('?')
    features['exclamation_count'] = text.count('!')
    features['quote_count'] = text.count('"') + text.count("'")
    
    if len(text) > 0:
        features['uppercase_ratio'] = sum(1 for c in text if c.isupper()) / len(text)
    else:
        features['uppercase_ratio'] = 0
    
    connectors = ['sonuÃ§ olarak', 'bununla birlikte', 'diÄŸer yandan', 'Ã¶te yandan', 
                  'kÄ±sacasÄ±', 'dolayÄ±sÄ±yla', 'bu nedenle', 'ayrÄ±ca', 'bunun yanÄ±nda']
    features['connector_count'] = sum(text.lower().count(c) for c in connectors)
    
    passive_markers = ['edilmek', 'yapÄ±lmak', 'olmak', 'gÃ¶rÃ¼lmek', 'dÃ¼ÅŸÃ¼nÃ¼lmek']
    features['passive_marker_count'] = sum(text.lower().count(p) for p in passive_markers)
    
    return features

@st.cache_resource
def load_models():
    model_path = "zeroGPT_final_model.pkl"
    vec_path = "zeroGPT_final_vectorizer.pkl"
    scaler_path = "zeroGPT_final_scaler.pkl"
    
    if not all(os.path.exists(p) for p in [model_path, vec_path, scaler_path]):
        return None, None, None
    
    model = joblib.load(model_path)
    vectorizer = joblib.load(vec_path)
    scaler = joblib.load(scaler_path)
    return model, vectorizer, scaler

def predict_text(text: str, model, vectorizer, scaler):
    """Metin tahmini yap - Hata yÃ¶netimi ile korumalÄ±"""
    try:
        cleaned = clean_text(text)
        
        # Ã–zellikleri bir kez hesapla (performans iyileÅŸtirmesi)
        features = extract_advanced_features(cleaned)
        
        # TF-IDF Ã¶zellikleri
        tfidf_features = vectorizer.transform([cleaned])
        
        # Ä°statistiksel Ã¶zellikleri kullan (tekrar hesaplama yok!)
        stat_features = pd.DataFrame([features])
        stat_features_scaled = scaler.transform(stat_features)
        
        # BirleÅŸtir ve tahmin yap
        combined = hstack([tfidf_features, stat_features_scaled])
        pred = model.predict(combined)[0]
        proba = model.predict_proba(combined)[0]
        
        return pred, proba, features
        
    except MemoryError:
        st.error("âŒ **Metin Ã§ok uzun!** LÃ¼tfen daha kÄ±sa bir metin deneyin (maksimum ~5000 kelime).")
        return None, None, None
        
    except ValueError as e:
        st.error(f"âŒ **GeÃ§ersiz veri hatasÄ±:** {str(e)}")
        st.info("ğŸ’¡ LÃ¼tfen metninizin dÃ¼zgÃ¼n TÃ¼rkÃ§e karakterler iÃ§erdiÄŸinden emin olun.")
        return None, None, None
        
    except Exception as e:
        st.error(f"âŒ **Beklenmeyen hata:** {str(e)}")
        st.warning("âš ï¸ LÃ¼tfen farklÄ± bir metin deneyin veya sayfayÄ± yenileyin.")
        return None, None, None

def analyze_sentences(text: str, model, vectorizer, scaler):
    """Her cÃ¼mleyi ayrÄ± ayrÄ± analiz et ve AI oranlarÄ±nÄ± dÃ¶ndÃ¼r"""
    # CÃ¼mlelere ayÄ±r
    sentences = [s.strip() for s in re.split(r'([.!?]+)', text) if s.strip()]
    
    # CÃ¼mle ve noktalama iÅŸaretlerini birleÅŸtir
    combined_sentences = []
    i = 0
    while i < len(sentences):
        if i + 1 < len(sentences) and sentences[i + 1] in ['.', '!', '?', '...']:
            combined_sentences.append(sentences[i] + sentences[i + 1])
            i += 2
        else:
            combined_sentences.append(sentences[i])
            i += 1
    
    results = []
    for sent in combined_sentences:
        if len(sent.strip()) < 10:  # Ã‡ok kÄ±sa cÃ¼mleler iÃ§in
            results.append({
                'text': sent,
                'is_ai': False,
                'ai_prob': 0.0,
                'human_prob': 1.0
            })
            continue
        
        try:
            cleaned = clean_text(sent)
            features = extract_advanced_features(cleaned)
            tfidf_features = vectorizer.transform([cleaned])
            stat_features = pd.DataFrame([features])
            stat_features_scaled = scaler.transform(stat_features)
            combined = hstack([tfidf_features, stat_features_scaled])
            
            pred = model.predict(combined)[0]
            proba = model.predict_proba(combined)[0]
            
            results.append({
                'text': sent,
                'is_ai': pred == 1,
                'ai_prob': proba[1],
                'human_prob': proba[0]
            })
        except:
            results.append({
                'text': sent,
                'is_ai': False,
                'ai_prob': 0.0,
                'human_prob': 1.0
            })
    
    return results

# Ana Uygulama
st.title("ğŸ¯ ZeroGPT TÃ¼rkÃ§e - Final Versiyon")
st.markdown("### GerÃ§ek ChatGPT Metinleriyle EÄŸitilmiÅŸ AI DedektÃ¶rÃ¼")

# BaÅŸarÄ± rozetleri
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("âœ… Accuracy", "99.98%")
with col2:
    st.metric("ğŸ¯ Model", "Gradient Boost")
with col3:
    st.metric("ğŸ“Š Ã–zellikler", "15K+ TF-IDF")

st.markdown("---")

model, vectorizer, scaler = load_models()

if model is None:
    st.error("âŒ Final model dosyalarÄ± bulunamadÄ±!")
    st.info("LÃ¼tfen Ã¶nce modeli eÄŸitin: `python3 retrain_with_real_chatgpt.py`")
    st.stop()

# Metin giriÅŸi
user_input = st.text_area(
    "ğŸ“ Analiz edilecek metni girin:",
    height=200,
    placeholder="Ã–rnek: Yapay zeka teknolojileri gÃ¼nÃ¼mÃ¼zde birÃ§ok sektÃ¶rde kullanÄ±lÄ±yor..."
)

if st.button("ğŸš€ Analiz Et", type="primary", use_container_width=True):
    if not user_input or len(user_input.strip()) < 20:
        st.warning("âš ï¸ LÃ¼tfen en az 20 karakter uzunluÄŸunda bir metin girin.")
    elif len(user_input.strip().split()) < 5:
        st.warning("âš ï¸ LÃ¼tfen en az 5 kelime iÃ§eren bir metin girin.")
    elif len(user_input.strip().split()) > 5000:
        st.warning("âš ï¸ Metin Ã§ok uzun! Maksimum 5000 kelime girebilirsiniz.")
    else:
        with st.spinner("ğŸ” DetaylÄ± analiz yapÄ±lÄ±yor..."):
            pred, proba, features = predict_text(user_input, model, vectorizer, scaler)
            
            # Hata kontrolÃ¼ - predict_text None dÃ¶ndÃ¼rdÃ¼yse dur
            if pred is None or proba is None or features is None:
                st.stop()  # Hata mesajÄ± zaten gÃ¶sterildi, devam etme
            
            # CÃ¼mle bazlÄ± analiz
            sentence_results = analyze_sentences(user_input, model, vectorizer, scaler)
            
            st.markdown("---")
            
            # Ana sonuÃ§ - sade ve anlaÅŸÄ±lÄ±r
            if pred == 0:
                st.success("# âœ… Ä°NSAN YAZISI")
                st.metric("GÃ¼ven OranÄ±", f"%{proba[0]*100:.1f}", delta="Ä°nsan")
            else:
                st.error("# ğŸ¤– YAPAY ZEKA YAZISI")
                st.metric("GÃ¼ven OranÄ±", f"%{proba[1]*100:.1f}", delta="AI")
            
            st.markdown("---")
            
            # ğŸ¨ CÃœMLE BAZLI VURGULAMA - AI cÃ¼mleleri sarÄ± renkte!
            st.markdown("### ğŸ” DetaylÄ± CÃ¼mle Analizi")
            st.markdown("**ğŸŸ¨ SarÄ± vurgulu** kÄ±sÄ±mlar AI tarafÄ±ndan yazÄ±lmÄ±ÅŸ, **â¬œ normal** kÄ±sÄ±mlar insan yazÄ±sÄ±:")
            
            # HTML oluÅŸtur - Beyaz arka plan ve siyah metin
            html_content = '''
            <div style="
                line-height: 2.2; 
                font-size: 18px; 
                padding: 25px; 
                background: #ffffff;
                color: #000000;
                border-radius: 10px; 
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                border: 2px solid #e0e0e0;
            ">'''
            
            ai_count = 0
            human_count = 0
            
            for result in sentence_results:
                text = result['text']
                is_ai = result['is_ai']
                ai_prob = result['ai_prob']
                
                # Yeni satÄ±rlarÄ± <br> tagÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                text_html = text.replace('\n', '<br>')
                
                if is_ai and ai_prob > 0.6:  # AI tespit eÅŸiÄŸi
                    ai_count += 1
                    # SarÄ± vurgulu AI cÃ¼mlesi - Ã§ok belirgin!
                    html_content += f'''
                    <span class="ai-sentence" style="
                        background: #FFD93D;
                        color: #000000;
                        padding: 6px 10px;
                        border-radius: 8px;
                        border-left: 5px solid #FF6B35;
                        margin: 3px;
                        display: inline-block;
                        font-weight: 600;
                        transition: all 0.3s ease;
                        cursor: help;
                        box-shadow: 0 2px 8px rgba(255, 217, 61, 0.5);
                    " title="ğŸ¤– AI OlasÄ±lÄ±ÄŸÄ±: %{ai_prob*100:.1f}">ğŸ¤– {text_html}</span> 
                    '''
                else:
                    human_count += 1
                    # Normal metin (insan) - aÃ§Ä±k gri arka plan
                    html_content += f'''<span style="
                        background: #f5f5f5;
                        color: #000000;
                        padding: 6px 10px;
                        margin: 3px;
                        display: inline-block;
                        border-radius: 5px;
                    ">ğŸ‘¤ {text_html}</span> '''
            
            html_content += '</div>'
            
            # CSS ile birlikte gÃ¶ster
            components.html(f"""
                <style>
                    @keyframes pulse {{
                        0%, 100% {{ box-shadow: 0 2px 8px rgba(255, 217, 61, 0.5); }}
                        50% {{ box-shadow: 0 4px 16px rgba(255, 217, 61, 0.8); }}
                    }}
                    .ai-sentence:hover {{
                        transform: scale(1.05);
                        box-shadow: 0 4px 16px rgba(255, 107, 53, 0.6) !important;
                        background: #FFC300 !important;
                    }}
                </style>
                {html_content}
            """, height=max(300, len(sentence_results) * 35))
            
            # Ä°statistikler
            st.markdown("---")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ¤– AI CÃ¼mleleri", f"{ai_count} adet", delta=f"%{(ai_count/(ai_count+human_count)*100) if (ai_count+human_count) > 0 else 0:.0f}")
            with col2:
                st.metric("ğŸ‘¤ Ä°nsan CÃ¼mleleri", f"{human_count} adet", delta=f"%{(human_count/(ai_count+human_count)*100) if (ai_count+human_count) > 0 else 0:.0f}")
            with col3:
                st.metric("ğŸ“ Toplam CÃ¼mle", f"{ai_count + human_count} adet")
            
            # OlasÄ±lÄ±k Ã§ubuklarÄ±
            st.markdown("---")
            st.markdown("### ğŸ“Š DetaylÄ± OlasÄ±lÄ±klar")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ‘¤ Ä°nsan**")
                st.progress(proba[0])
                st.write(f"**%{proba[0]*100:.2f}**")
            
            with col2:
                st.markdown("**ğŸ¤– Yapay Zeka**")
                st.progress(proba[1])
                st.write(f"**%{proba[1]*100:.2f}**")
            
            # Ã–zellik analizi
            st.markdown("---")
            st.markdown("### ğŸ”¬ Ã–zellik Analizi")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ğŸ“ Kelime", f"{features['word_count']:.0f}")
                st.metric("ğŸ“ CÃ¼mle", f"{features['sentence_count']:.0f}")
            
            with col2:
                st.metric("ğŸ¯ Ã‡eÅŸitlilik", f"{features['lexical_diversity']:.2f}")
                st.metric("ğŸ’¥ Burstiness", f"{features['burstiness']:.2f}")
            
            with col3:
                st.metric("ğŸ”¢ Entropi", f"{features['char_entropy']:.2f}")
                st.metric("ğŸ”— BaÄŸlaÃ§", f"{features['connector_count']:.0f}")
            
            with col4:
                st.metric("ğŸ“Œ Stopword", f"{features['stopword_ratio']:.2f}")
                st.metric("â“ Soru", f"{features['question_mark_count']:.0f}")
            
            # Yorum
            st.markdown("---")
            with st.expander("ğŸ’¡ Bu SonuÃ§ Ne Anlama Geliyor?"):
                if pred == 1:
                    st.info("""
                    **AI Tespit Ä°ÅŸaretleri:**
                    - DÃ¼zenli ve tutarlÄ± cÃ¼mle yapÄ±sÄ± (dÃ¼ÅŸÃ¼k burstiness)
                    - Formal ve akademik dil kullanÄ±mÄ±
                    - BaÄŸlaÃ§ yoÄŸunluÄŸu ("sonuÃ§ olarak", "bununla birlikte")
                    - YapÄ±landÄ±rÄ±lmÄ±ÅŸ paragraf dÃ¼zeni
                    - Tekrarlayan kalÄ±plar ve kelime seÃ§imleri
                    """)
                else:
                    st.success("""
                    **Ä°nsan YazÄ± Ä°ÅŸaretleri:**
                    - DeÄŸiÅŸken cÃ¼mle uzunluklarÄ± (yÃ¼ksek burstiness)
                    - DoÄŸal dil akÄ±ÅŸÄ± ve spontane ifadeler
                    - KiÅŸisel vurgular ve Ã¼nlemler
                    - KonuÅŸma diline yakÄ±n Ã¼slup
                    - Ã–zgÃ¼n kelime seÃ§imleri
                    """)

# Ã–rnek metinler
st.markdown("---")
with st.expander("ğŸ“š Ã–rnek Metinlerle Test Edin"):
    st.markdown("**AI Metni:**")
    st.code("""Teknoloji, insanlÄ±ÄŸÄ±n ilerlemesini hÄ±zlandÄ±ran en gÃ¼Ã§lÃ¼ araÃ§lardan biridir. 
GÃ¼nÃ¼mÃ¼zde yapay zekÃ¢, otomasyon ve bÃ¼yÃ¼k veri analizleri sayesinde Ã¼retimden 
saÄŸlÄ±ÄŸa kadar her alanda verimlilik artÄ±ÅŸÄ± saÄŸlanmaktadÄ±r.""")
    
    st.markdown("**Ä°nsan Metni:**")
    st.code("""BugÃ¼n arkadaÅŸÄ±mla sahilde yÃ¼rÃ¼dÃ¼k, hava Ã§ok gÃ¼zeldi yaa! 
Deniz kenarÄ±nda oturup sohbet ettik. AkÅŸam da gÃ¼zel bir yemek yedik.""")

# Model bilgisi
st.markdown("---")
with st.expander("â„¹ï¸ Model HakkÄ±nda"):
    st.markdown("""
    ### ğŸ“ ZeroGPT Final Model
    
    **EÄŸitim Verisi:**
    - ğŸ“Š 20,500+ TÃ¼rkÃ§e metin
    - âœ… GerÃ§ek ChatGPT Ã¶rnekleri dahil
    - ğŸ”„ Dengeli veri seti (%50 AI, %50 Ä°nsan)
    
    **Teknik Ã–zellikler:**
    - ğŸš€ Gradient Boosting Classifier (200 trees)
    - ğŸ“ˆ 15,000 TF-IDF Ã¶zellikleri (1-3 gram)
    - ğŸ”¬ 20+ istatistiksel Ã¶zellik
    - ğŸ¯ %99.98 test accuracy
    
    **Tespit Edilen Ã–zellikler:**
    - Burstiness (cÃ¼mle varyasyonu)
    - Lexical Diversity (kelime Ã§eÅŸitliliÄŸi)
    - Character Entropy (bilgi yoÄŸunluÄŸu)
    - Connector Usage (baÄŸlaÃ§ kullanÄ±mÄ±)
    - Syntactic Patterns (sÃ¶zdizimi kalÄ±plarÄ±)
    
    **Version:** 1.0 Final (GerÃ§ek ChatGPT ile eÄŸitilmiÅŸ)
    """)

st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>ğŸ¯ ZeroGPT TÃ¼rkÃ§e Final v1.0 - GerÃ§ek ChatGPT DedektÃ¶rÃ¼</div>",
    unsafe_allow_html=True
)

